{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1: Write a jupyter notebook to use the EM algorithm to adapt the means of a 2D Gaussian\n",
    "mixture model with fixed covariance matrices (which can be the same). The notebook should show the\n",
    "mathematical derivation for the EM equations. Follow the style and plots of the demonstration in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, copy, gzip, pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import chi2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deriving the EM Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can derive the equations for the Expectation-Maximization algorithm by starting with the multivariate Gaussian distribution:  \n",
    "$p(x|\\mu,\\sum) = N(x|\\mu,\\sum) = \\frac{exp(-\\frac{1}{2}(x-\\mu)^{T}\\sum^{-1}(x-\\mu))}{(2\\pi)^{D/2}|\\sum|^{\\frac{1}{2}}}$  \n",
    "and taking its log:  \n",
    "$ln(p(x|\\mu,\\sum)) = -\\frac{1}{2}ln(2\\pi)-\\frac{1}{2}ln|\\sum|-\\frac{1}{2}(x-\\mu)^{T}\\sum^{-1}(x-\\mu)$  \n",
    "We can then take the derivative of this log with respect to the parameters $\\mu$ and $\\sum$ and set them to 0 to get their maximum values:  \n",
    "$\\frac{d(ln(p(x|\\mu,\\sum)))}{d\\mu} = 0 \\rightarrow \\mu_{k} = \\sum_{n} p_{n,k}x^{(n)}/p_{k}$  \n",
    "$\\frac{d(ln(p(x|\\mu,\\sum)))}{d\\sum} = 0 \\rightarrow \\sum_{k} = \\sum_{n} p_{n,k}(x^{(n)}-\\mu_{k})(x^{(n)}-\\mu_{k})^{T}/p_{k}$  \n",
    "This gives us our first two equations from the M-step.  The remaining equations follow directly from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And so we arrive at our final EM Equations:  \n",
    "E-step: We compute $p_{n,k}$ and $p_k$:  \n",
    "$p_{n,k} = p(c_{k}|x^{(n)},\\theta_{1:K})$  \n",
    "$p_k = \\sum_{n}p_{n,k}$  \n",
    "M-step: For each class, we compute the updated mean $\\mu_{k}$, covariance $\\sum_{k}$, and class prior $p(c_{k})$:  \n",
    "$\\mu_{k} = \\sum_{n} p_{n,k}x^{(n)}/p_{k}$  \n",
    "$\\sum_{k} = \\sum_{n} p_{n,k}(x^{(n)}-\\mu_{k})(x^{(n)}-\\mu_{k})^{T}/p_{k}$  \n",
    "$p(c_{k}) = p_{k}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/faithful.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a2fd4461b416>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/faithful.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdataReader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# initialize an empty array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataReader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/faithful.txt'"
     ]
    }
   ],
   "source": [
    "# TODO: find better data\n",
    "with open('data/faithful.txt', 'rt') as csvfile:\n",
    "    dataReader = csv.reader(csvfile, delimiter=' ')\n",
    "    # initialize an empty array\n",
    "    data = []\n",
    "    for row in dataReader:\n",
    "        data.append(np.array(row).astype(np.float))\n",
    "    # convert data into a numpy array\n",
    "    data = np.asarray(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngmm = 2 # quantity of Gaussian Mixture Model\n",
    "mu = np.asarray([[2, 70], \n",
    "                 [4, 80]]\n",
    "               ).astype('float')\n",
    "\n",
    "sigma = np.asarray([[[1, 0], \n",
    "                     [0, 3]], \n",
    "                    [[0.5, 0.2], \n",
    "                     [0.2, 0.6]]]\n",
    "                  ).astype('float')\n",
    "def covmatIsLegal(sigma):\n",
    "    for covmat in sigma:\n",
    "        if not(np.allclose(covmat, covmat.T)) or np.any(np.linalg.eigvals(covmat) <= 0):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "print(\"Convariance Matrices are Legal? : %r\" % covmatIsLegal(sigma))\n",
    "gmm = [{'mean': mu[m], 'covariance': sigma[m], 'prior': 1.0/ngmm} for m in range(ngmm)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d938d9bd56b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mplotGaussianModel2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'covariance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolorPicker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mgmmplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgmm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "def plotGaussianModel2D(mu, sigma, pltopt='k'):\n",
    "    if sigma.any():\n",
    "        # calculate ellipse constants\n",
    "        c = chi2.ppf(0.9, 2) # use confidence interval 0.9\n",
    "        # get eigen vector and eigen values\n",
    "        eigenValue, eigenVector = np.linalg.eig(sigma)\n",
    "        # calculate points on ellipse\n",
    "        t = np.linspace(0, 2*np.pi, 100) # draw 100 points\n",
    "        u = [np.cos(t), np.sin(t)]\n",
    "        w = c * eigenVector.dot(np.diag(np.sqrt(eigenValue)).dot(u))\n",
    "        z = w.T + mu\n",
    "    else:\n",
    "        z = mu\n",
    "    # plot ellipse by connecting sample points on curve\n",
    "    plt.plot(z[:,0], z[:,1], pltopt)\n",
    "    \n",
    "def colorPicker(index):\n",
    "    colors = 'rgbcmyk'\n",
    "    return colors[np.remainder(index, len(colors))]\n",
    "\n",
    "def gmmplot(data, gmm):\n",
    "    # plot data points\n",
    "    plt.scatter(data[:, 0], data[:, 1], s=4)\n",
    "    # plot Gaussian model\n",
    "    color = 'rgb'\n",
    "    for index, model in enumerate(gmm):\n",
    "        plotGaussianModel2D(model['mean'], model['covariance'], colorPicker(index))\n",
    "\n",
    "gmmplot(data, gmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the Mixture Model with the EM Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea of optimization process here is iteratively run **expectation** and **maximization**, and stop when the stop criteria is achived. Here, we use predefined number of iterations, **but we recommend you extend it into more comprehensive ones**. Also remember to show the progress of optimization with help of **gmmplot**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gmmlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7b1f22158cf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgmmlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexpectation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximization_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# make a true copy of our model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgmmcp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgmm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gmmlib'"
     ]
    }
   ],
   "source": [
    "from gmmlib import expectation, maximization, maximization_mean\n",
    "\n",
    "# make a true copy of our model\n",
    "gmmcp = copy.deepcopy(gmm)\n",
    "\n",
    "# create figure\n",
    "plt.figure(figsize=(16, 8))\n",
    "# improve model with EM-Algorithm\n",
    "for i in range(5):\n",
    "    # plot current status\n",
    "    plt.subplot(231 + i)\n",
    "    gmmplot(data, gmmcp)\n",
    "    # excute EM-Algorithm\n",
    "    for j in range(5):\n",
    "        posterior = expectation(data, gmmcp)\n",
    "        gmmcp = maximization_mean(posterior, data, gmmcp)\n",
    "# plot final status\n",
    "plt.subplot(236)\n",
    "gmmplot(data,gmmcp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
